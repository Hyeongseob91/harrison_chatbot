# ğŸ§ª í…ŒìŠ¤íŠ¸

> ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë° í†µí•© í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

pytestë¥¼ ì‚¬ìš©í•œ í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ì…ë‹ˆë‹¤.
ë‹¨ìœ„ í…ŒìŠ¤íŠ¸(Unit Tests), í†µí•© í…ŒìŠ¤íŠ¸(Integration Tests), E2E í…ŒìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ë©°,
Mock ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì™¸ë¶€ ì˜ì¡´ì„±ì„ ê²©ë¦¬í•©ë‹ˆë‹¤.

## ğŸ“ í´ë” êµ¬ì¡°

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py             # pytest fixtures ë° ì„¤ì •
â”‚
â”œâ”€â”€ unit/                   # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (ë¹ ë¦„, ê²©ë¦¬)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_nodes/         # ë…¸ë“œ í…ŒìŠ¤íŠ¸
â”‚   â”‚   â”œâ”€â”€ test_user_input_node.py
â”‚   â”‚   â”œâ”€â”€ test_retrieval_node.py
â”‚   â”‚   â”œâ”€â”€ test_response_node.py
â”‚   â”‚   â””â”€â”€ test_synthesis_node.py
â”‚   â”œâ”€â”€ test_services/      # ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
â”‚   â”‚   â”œâ”€â”€ test_llm_service.py
â”‚   â”‚   â”œâ”€â”€ test_embedding_service.py
â”‚   â”‚   â””â”€â”€ test_qdrant_service.py
â”‚   â””â”€â”€ test_utils/         # ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸
â”‚       â”œâ”€â”€ test_logger.py
â”‚       â””â”€â”€ test_validators.py
â”‚
â”œâ”€â”€ integration/            # í†µí•© í…ŒìŠ¤íŠ¸ (ëŠë¦¼, ì‹¤ì œ ì„œë¹„ìŠ¤ ì‚¬ìš©)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_workflow.py    # ì „ì²´ LangGraph ì›Œí¬í”Œë¡œìš°
â”‚   â”œâ”€â”€ test_api.py         # FastAPI ì—”ë“œí¬ì¸íŠ¸
â”‚   â””â”€â”€ test_django_api.py  # Django API
â”‚
â””â”€â”€ e2e/                    # End-to-End í…ŒìŠ¤íŠ¸
    â”œâ”€â”€ __init__.py
    â””â”€â”€ test_full_flow.py   # ì „ì²´ ì‹œìŠ¤í…œ í”Œë¡œìš°
```

## ğŸš€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install pytest pytest-asyncio pytest-cov pytest-mock
```

### ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸
pytest

# verbose ëª¨ë“œ
pytest -v

# ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨
pytest -x
```

### íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰

```bash
# ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë§Œ
pytest tests/unit

# í†µí•© í…ŒìŠ¤íŠ¸ë§Œ
pytest tests/integration

# íŠ¹ì • íŒŒì¼
pytest tests/unit/test_nodes/test_response_node.py

# íŠ¹ì • í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
pytest tests/unit/test_nodes/test_response_node.py::test_response_node_success
```

### ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸

```bash
# ì»¤ë²„ë¦¬ì§€ì™€ í•¨ê»˜ í…ŒìŠ¤íŠ¸
pytest --cov=app tests/

# HTML ë¦¬í¬íŠ¸ ìƒì„±
pytest --cov=app --cov-report=html tests/

# htmlcov/index.html ì—´ê¸°
open htmlcov/index.html
```

### ë§ˆì»¤ ì‚¬ìš©

```bash
# ëŠë¦° í…ŒìŠ¤íŠ¸ ì œì™¸
pytest -m "not slow"

# ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ë§Œ
pytest -m "asyncio"
```

## ğŸ› ï¸ conftest.py (Fixtures)

```python
# tests/conftest.py
import pytest
import asyncio
from typing import Generator
from app.services.interfaces.llm_interface import LLMInterface
from app.services.interfaces.embedding_interface import EmbeddingInterface
from app.services.interfaces.vector_store_interface import VectorStoreInterface

# ==== Event Loop Fixture (ë¹„ë™ê¸° í…ŒìŠ¤íŠ¸ìš©) ====

@pytest.fixture(scope="session")
def event_loop():
    """ì´ë²¤íŠ¸ ë£¨í”„ ìƒì„±"""
    loop = asyncio.get_event_loop_policy().new_event_loop()
    yield loop
    loop.close()


# ==== Mock Services ====

class MockLLMService(LLMInterface):
    """í…ŒìŠ¤íŠ¸ìš© Mock LLM ì„œë¹„ìŠ¤"""

    async def generate(self, **kwargs) -> str:
        return "ëª¨ì˜ LLM ì‘ë‹µì…ë‹ˆë‹¤"

    async def stream(self, **kwargs):
        for chunk in ["ëª¨ì˜ ", "ìŠ¤íŠ¸ë¦¬ë° ", "ì‘ë‹µ"]:
            yield chunk

    @property
    def last_token_count(self) -> int:
        return 100


class MockEmbeddingService(EmbeddingInterface):
    """í…ŒìŠ¤íŠ¸ìš© Mock Embedding ì„œë¹„ìŠ¤"""

    async def embed(self, text: str) -> list[float]:
        # ê³ ì •ëœ ë²¡í„° ë°˜í™˜
        return [0.1] * 1536


class MockVectorStore(VectorStoreInterface):
    """í…ŒìŠ¤íŠ¸ìš© Mock Vector Store"""

    async def search(self, **kwargs) -> list[dict]:
        return [
            {
                "content": "í…ŒìŠ¤íŠ¸ ë¬¸ì„œ ë‚´ìš©",
                "metadata": {
                    "filename": "test.pdf",
                    "page": 1,
                    "score": 0.9
                }
            }
        ]


# ==== Fixtures ====

@pytest.fixture
def mock_llm_service(monkeypatch):
    """LLM ì„œë¹„ìŠ¤ë¥¼ Mockìœ¼ë¡œ êµì²´"""
    monkeypatch.setattr(
        "app.services.factory.get_llm_service",
        lambda: MockLLMService()
    )


@pytest.fixture
def mock_embedding_service(monkeypatch):
    """Embedding ì„œë¹„ìŠ¤ë¥¼ Mockìœ¼ë¡œ êµì²´"""
    monkeypatch.setattr(
        "app.services.factory.get_embedding_service",
        lambda: MockEmbeddingService()
    )


@pytest.fixture
def mock_vector_store(monkeypatch):
    """Vector Storeë¥¼ Mockìœ¼ë¡œ êµì²´"""
    monkeypatch.setattr(
        "app.services.factory.get_vector_store",
        lambda: MockVectorStore()
    )


@pytest.fixture
def sample_chat_state():
    """ìƒ˜í”Œ ChatState"""
    return {
        "messages": [],
        "query": "í…ŒìŠ¤íŠ¸ ì§ˆë¬¸",
        "retrieved_docs": [],
        "context": "",
        "response": "",
        "metadata": {}
    }
```

## ğŸ”¬ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

### ë…¸ë“œ í…ŒìŠ¤íŠ¸

```python
# tests/unit/test_nodes/test_response_node.py
import pytest
from app.nodes.chat_process.response_node import response_node
from app.nodes.graph_state.schemas import ChatState

@pytest.mark.asyncio
async def test_response_node_success(mock_llm_service, sample_chat_state):
    """response_nodeê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸"""

    # Given: í…ŒìŠ¤íŠ¸ ìƒíƒœ
    state = ChatState(
        **sample_chat_state,
        context="í…ŒìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸",
        retrieved_docs=[
            {
                "content": "ë¬¸ì„œ ë‚´ìš©",
                "metadata": {"filename": "test.pdf", "page": 1, "score": 0.9}
            }
        ]
    )

    # When: ë…¸ë“œ ì‹¤í–‰
    result = await response_node(state)

    # Then: ê²€ì¦
    assert "response" in result
    assert len(result["response"]) > 0
    assert "metadata" in result
    assert "tokens_used" in result["metadata"]


@pytest.mark.asyncio
async def test_response_node_empty_context(mock_llm_service, sample_chat_state):
    """ë¹ˆ ì»¨í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""

    state = ChatState(**sample_chat_state, context="", retrieved_docs=[])

    result = await response_node(state)

    # ë¹ˆ ì»¨í…ìŠ¤íŠ¸ì—¬ë„ ì‘ë‹µ ìƒì„±
    assert "response" in result
```

### ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸

```python
# tests/unit/test_services/test_llm_service.py
import pytest
from app.services.implementations.openai_llm_service import OpenAILLMService

@pytest.mark.asyncio
async def test_llm_service_generate():
    """LLM ì„œë¹„ìŠ¤ generate ë©”ì„œë“œ í…ŒìŠ¤íŠ¸"""

    # Mock API Keyë¡œ ì´ˆê¸°í™”
    service = OpenAILLMService(api_key="test-key")

    # API í˜¸ì¶œ Mock (ì‹¤ì œ í˜¸ì¶œ ë°©ì§€)
    # pytest-mock ì‚¬ìš©
    ...


@pytest.mark.asyncio
async def test_llm_service_stream():
    """LLM ì„œë¹„ìŠ¤ stream ë©”ì„œë“œ í…ŒìŠ¤íŠ¸"""
    ...
```

## ğŸ”— í†µí•© í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ

### ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_workflow.py
import pytest
from app.main import app as langgraph_app
from langchain_core.messages import HumanMessage

@pytest.mark.asyncio
@pytest.mark.slow
async def test_full_workflow():
    """ì „ì²´ LangGraph ì›Œí¬í”Œë¡œìš° í†µí•© í…ŒìŠ¤íŠ¸"""

    # Given: ì´ˆê¸° ìƒíƒœ
    initial_state = {
        "messages": [HumanMessage(content="RAGë€ ë¬´ì—‡ì¸ê°€ìš”?")],
        "query": "",
        "retrieved_docs": [],
        "context": "",
        "response": "",
        "metadata": {}
    }

    # When: ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = await langgraph_app.ainvoke(initial_state)

    # Then: ê²€ì¦
    assert result["response"] != ""
    assert len(result["retrieved_docs"]) > 0
    assert result["context"] != ""
    assert "tokens_used" in result["metadata"]
```

### API í…ŒìŠ¤íŠ¸

```python
# tests/integration/test_api.py
import pytest
from fastapi.testclient import TestClient
from app.api.main import app

client = TestClient(app)

def test_chat_invoke_endpoint():
    """ì±„íŒ… invoke ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""

    response = client.post(
        "/chat/invoke",
        json={"query": "í…ŒìŠ¤íŠ¸ ì§ˆë¬¸", "session_id": "test123"}
    )

    assert response.status_code == 200
    data = response.json()
    assert "response" in data
    assert "metadata" in data


def test_document_upload_endpoint():
    """ë¬¸ì„œ ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸"""

    with open("tests/fixtures/sample.pdf", "rb") as f:
        response = client.post(
            "/documents/upload",
            files={"file": ("sample.pdf", f, "application/pdf")}
        )

    assert response.status_code == 201
    data = response.json()
    assert "document_id" in data
```

## ğŸ­ Mock íŒ¨í„´

### ì™¸ë¶€ API Mock

```python
import pytest
from unittest.mock import AsyncMock, patch

@pytest.mark.asyncio
async def test_with_mocked_openai():
    """OpenAI APIë¥¼ Mockìœ¼ë¡œ í…ŒìŠ¤íŠ¸"""

    with patch("openai.AsyncOpenAI") as MockOpenAI:
        # Mock ì„¤ì •
        mock_instance = MockOpenAI.return_value
        mock_instance.chat.completions.create = AsyncMock(
            return_value={
                "choices": [{"message": {"content": "ëª¨ì˜ ì‘ë‹µ"}}],
                "usage": {"total_tokens": 100}
            }
        )

        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        ...
```

### ë°ì´í„°ë² ì´ìŠ¤ Mock

```python
import pytest
from sqlalchemy import create_engine
from sqlalchemy.orm import Session

@pytest.fixture
def test_db():
    """í…ŒìŠ¤íŠ¸ìš© ì¸ë©”ëª¨ë¦¬ DB"""
    engine = create_engine("sqlite:///:memory:")
    # í…Œì´ë¸” ìƒì„±
    Base.metadata.create_all(engine)

    session = Session(engine)
    yield session

    session.close()
```

## ğŸ“Š í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ëª©í‘œ

| ë ˆì´ì–´ | ì»¤ë²„ë¦¬ì§€ ëª©í‘œ |
|--------|--------------|
| Domain | 100% |
| Nodes | 90%+ |
| Services | 85%+ |
| API | 80%+ |
| Utils | 95%+ |

## ğŸ“– ì°¸ê³  ìë£Œ

- [pytest ê³µì‹ ë¬¸ì„œ](https://docs.pytest.org/)
- [pytest-asyncio](https://pytest-asyncio.readthedocs.io/)
- [pytest-cov](https://pytest-cov.readthedocs.io/)

---

**ì² ì €í•œ í…ŒìŠ¤íŠ¸ë¡œ ì•ˆì •ì ì¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì„¸ìš”.**
